<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Portfolio for 41118 AI Project, by Milo Boyd and Liam Calder;.">
  <meta name="keywords" content="41118">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>41118 TetrisAI Project Portfolio</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Tetris AI</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/miloboyd">Milo Boyd</a>,
            </span>
            <span class="author-block">
              <a href="https://github.com/Liam5347">Liam Calder</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">41118 Project Portfolio</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links" style="margin-bottom: 10px;">
              <!-- PDF Link. 
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>-->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="#video"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/miloboyd/tetrisAI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/tetris_AI.jpeg"
            class="teaser-image"
            style="width: 50%; height: auto; margin: 0 auto 20px auto; display: block;"
            alt="Teaser."/>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf"></span> This portfolio details the design and structure of a trained AI model to complete tetris. This AI model utilises reinforcement learning and a DQN algorithm to calculate optimal moves based on the board state.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Team members</h2>
      <div class="columns is-centered">
        <div class="column is-narrow has-text-centered">
          <img src="./static/images/staff/miloface.jpeg"
            class="image is-128x128"
            style="border-radius: 50%; margin: 0 auto; object-fit: cover; width: 128px; height: 128px;"
            alt="Milo Boyd"/>
          <p class="has-text-weight-semibold mt-3">Milo Boyd</p>
        </div>
        <div class="column is-narrow has-text-centered">
          <img src="./static/images/staff/liamface.jpeg"
            class="image is-128x128"
            style="border-radius: 50%; margin: 0 auto; object-fit: cover; width: 128px; height: 128px;"
            alt="Liam Calder"/>
          <p class="has-text-weight-semibold mt-3">Liam Calder</p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            A Deep Q-Network (DQN) implementation that learns to play Tetris using reinforcement learning with advanced board state analysis and sophisticated reward engineering.
          </p>
          <h3 class="title is-4">Project Overview</h3>
          <p>
            This project implements a DQN agent that learns to play Tetris through reinforcement learning, using a multi-channel observation space and carefully crafted reward functions. The AI analyzes board states through multiple features including holes, bumpiness, height factors, and Tetris setup detection to make strategic decisions about piece placement.
          </p>
          <p>
            The implementation uses a 3-channel observation system that captures the current board state, active piece position, and next piece information, allowing the AI to plan ahead and make more informed decisions.
          </p>
          <p>
            The video below explains our approach and demonstrates the AI in action.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 id="video" class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/lIt-SdcPzg8?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div> 
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <!-- DQN training - centered -->
      <div class="column is-8">
        <h2 class="title is-3 has-text-centered">DQN Training</h2>
        <div class="content">
          <p class="has-text-centered">
            Sample of the reward convergence plot over episode count.
          </p>
          <img src="./static/images/results/training.png"
            class="teaser-image"
            style="display: block; margin: 0 auto; max-width: 100%;"
            alt="DQN Training Results"/>
        </div>
      </div>
    </div>
    <!--/ DQN training. -->

    <!-- Results Discussion. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results Discussion and Reflection</h2>

        <div class="content has-text-justified">
          <h3 class="title is-4">Limitations</h3>
          <p>
            Our project faced several critical limitations that prevented the AI from achieving acceptable performance:
          </p>
          
          <h4 class="title is-5">Technical Issues</h4>
          <ul>
            <li><strong>Tuning reward weights:</strong> Finding the optimal balance between different reward components proved extremely challenging, with the model often optimizing for unintended behaviors.</li>
            <li><strong>Achieving stable network training:</strong> The training process exhibited high variance and instability, making it difficult to achieve consistent improvements.</li>
            <li><strong>Network struggles interpreting game state:</strong> Despite our 3-channel observation design, the network appeared unable to effectively parse and understand the spatial relationships in the game board.</li>
          </ul>

          <h4 class="title is-5">Core Problem</h4>
          <p>
            The fundamental issue was that the AI never showed meaningful skill improvement despite extensive parameter tuning and architectural adjustments. This lack of progress created a negative feedback loop - without positive results to build upon, it became increasingly difficult to maintain development momentum and iterate effectively on the design.
          </p>

          <h3 class="title is-4">Challenges</h3>
          <p>
            <strong>DQN Model Limitations:</strong> Our choice of a simple DQN architecture may have been fundamentally inadequate for the complexity of Tetris. The model demonstrated only rudimentary ability to manipulate game pieces but lacked the sophisticated decision-making required to play at or beyond human level. The poor training results suggest that either our implementation was flawed or the basic DQN approach was insufficient for this task.
          </p>

          <h3 class="title is-4">Potential Improvements</h3>
          <p>
            <strong>CNN Architecture:</strong> A critical insight from our experience is that a Convolutional Neural Network (CNN) would likely be more suitable for processing the spatial 3-channel board representation. CNNs excel at extracting spatial features and patterns, which could help the model better understand board configurations without requiring an excessively large input space. This approach could significantly improve both training efficiency and the model's ability to recognize important game patterns.
          </p>

          <h3 class="title is-4">Conclusion</h3>
          <p>
            While our results were disappointing, the project provided valuable learning experiences. Key takeaways include:
          </p>
          <ul>
            <li>Earlier investment in exploring alternative AI models (such as Policy Gradient methods or Actor-Critic architectures) rather than persisting with DQN could have yielded better results.</li>
            <li>Reducing state space inputs is crucial for improving training time and reducing overfitting - our current representation may have been too complex.</li>
            <li>CNN architectures are likely essential for processing spatial game states effectively, as they can capture local patterns and hierarchical features that fully-connected layers struggle to learn.</li>
          </ul>
          <p>
            Future work should focus on implementing a CNN-based architecture for state processing, exploring more advanced reinforcement learning algorithms, and developing more sophisticated reward shaping techniques to guide the learning process more effectively.
          </p>
        </div>
      </div>
    </div>
    <!--/ Results Discussion. -->

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of the  website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>